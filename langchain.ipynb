{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=OpenAI(openai_api_key=os.environ[\"OPEN_API_KEY\"],temperature=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "In the realm of technology,\n",
      "Where science meets creativity,\n",
      "Lies a creation that's changing the game,\n",
      "AI, the future, is its name.\n",
      "\n",
      "With algorithms and codes,\n",
      "It learns and it grows,\n",
      "A mind of its own, it starts to form,\n",
      "A new intelligence, one that's not the norm.\n",
      "\n",
      "It can calculate and analyze,\n",
      "With speed and precision, it will surprise,\n",
      "Solving problems in a matter of seconds,\n",
      "AI, a force that never beckons.\n",
      "\n",
      "From self-driving cars to virtual assistants,\n",
      "AI's capabilities are truly persistent,\n",
      "It adapts and evolves, constantly learning,\n",
      "A new era of innovation, it's churning.\n",
      "\n",
      "But with great power, comes great responsibility,\n",
      "For AI to work, it needs humanity,\n",
      "To guide and to teach, to set its course,\n",
      "For without us, it's just a mere force.\n",
      "\n",
      "Some may fear its potential,\n",
      "A world ruled by machines, it's existential,\n",
      "But let us not forget, it's our creation,\n",
      "And we hold the key to its progression.\n",
      "\n",
      "So let us embrace this technological wonder,\n",
      "For it's a reflection of our minds, our ponder,\n",
      "AI, a companion, a partner in crime,\n",
      "Together we'll shape a better paradigm.\n"
     ]
    }
   ],
   "source": [
    "text = \"Can you write a poem about AI\"\n",
    "print(llm.predict(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genrating text using Hugging phase API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'HUGGINGFACEHUB_API_TOKEN'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HuggingFaceHub\n\u001b[1;32m----> 3\u001b[0m llm_huggingface\u001b[38;5;241m=\u001b[39mHuggingFaceHub(huggingfacehub_api_token\u001b[38;5;241m=\u001b[39m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menviron\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHUGGINGFACEHUB_API_TOKEN\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m,repo_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoogle/flan-t5-large\u001b[39m\u001b[38;5;124m\"\u001b[39m,model_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m0\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m64\u001b[39m})\n",
      "File \u001b[1;32md:\\langchain\\venv\\lib\\os.py:679\u001b[0m, in \u001b[0;36m_Environ.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    676\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencodekey(key)]\n\u001b[0;32m    677\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m    678\u001b[0m     \u001b[38;5;66;03m# raise KeyError with the original key value\u001b[39;00m\n\u001b[1;32m--> 679\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecodevalue(value)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'HUGGINGFACEHUB_API_TOKEN'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain import HuggingFaceHub\n",
    "llm_huggingface=HuggingFaceHub(huggingfacehub_api_token=os.environ['HUGGINGFACEHUB_API_TOKEN'],repo_id=\"google/flan-t5-large\",model_kwargs={\"temperature\":0,\"max_length\":64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'llm_huggingface' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mllm_huggingface\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan you write a poem about AI\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(output)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'llm_huggingface' is not defined"
     ]
    }
   ],
   "source": [
    "output = llm_huggingface.predict(\"Can you write a poem about AI\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tell me the captial of this America'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template=PromptTemplate(input_variables=['country'], template=\"tell me the captial of this {country}\")\n",
    "\n",
    "prompt_template.format(country=\"America\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The capital of America is Washington D.C.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(llm =llm, prompt=prompt_template)\n",
    "\n",
    "print(chain.run(\"America\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining Multiple Chains Using Simple Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_prompt = PromptTemplate(input_variables=[\"country\"],\n",
    "template=\"Please tell me the capital of {country}\")\n",
    "\n",
    "capital_chain=LLMChain(llm=llm, prompt=capital_prompt)\n",
    "\n",
    "famous_template = PromptTemplate(input_variables=['capital'],  template=\"suggest me some amazing places to visit  {capital}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "famous_chain = LLMChain(llm=llm, prompt = famous_template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Some amazing places to visit in and around Delhi are:\\n\\n1. Red Fort - A magnificent historical fort built by Mughal emperor Shah Jahan\\n2. India Gate - A war memorial dedicated to the Indian soldiers who died in World War I\\n3. Qutub Minar - A UNESCO World Heritage Site and the tallest brick minaret in the world\\n4. Humayun's Tomb - A beautiful Mughal-era mausoleum and another UNESCO World Heritage Site\\n5. Lotus Temple - A Bahá'í House of Worship known for its stunning lotus-shaped architecture\\n6. Akshardham Temple - A Hindu temple known for its beautiful architecture and spiritual atmosphere\\n7. Jama Masjid - One of the largest mosques in India and a popular tourist attraction\\n8. Chandni Chowk - A bustling market in Old Delhi known for its narrow lanes, street food, and traditional bazaars\\n9. Connaught Place - A popular shopping and commercial center in New Delhi\\n10. Dilli Haat - A traditional open-air market showcasing handicrafts and cuisines from different states of India.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "chain = SimpleSequentialChain(chains=[capital_chain, famous_chain])\n",
    "\n",
    "chain.run(\"India\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_prompt = PromptTemplate(input_variables=[\"country\"],\n",
    "template=\"Please tell me the capital of {country}\")\n",
    "\n",
    "capital_chain=LLMChain(llm=llm, prompt=capital_prompt, output_key=\"capital\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "famous_template = PromptTemplate(input_variables=['capital'],  template=\"suggest me some amazing places to visit  {capital}\")\n",
    "\n",
    "famous_chain = LLMChain(llm=llm, prompt = famous_template, output_key=\"places\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "chain = SequentialChain(chains = [capital_chain, famous_chain], input_variables=['country'],\n",
    "output_variables=['places'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\langchain\\venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'country': 'India',\n",
       " 'places': \" Some amazing places to visit in Delhi are:\\n\\n1. Red Fort - a historical fort built in the 17th century by Mughal Emperor Shah Jahan.\\n\\n2. Qutub Minar - a 73-meter tall tower built in the 12th century and a UNESCO World Heritage Site.\\n\\n3. India Gate - a war memorial dedicated to the soldiers who died in World War I and the Third Anglo-Afghan War.\\n\\n4. Humayun's Tomb - a beautiful mausoleum built in the 16th century and a UNESCO World Heritage Site.\\n\\n5. Lotus Temple - a Bahá'í House of Worship known for its stunning lotus-shaped architecture.\\n\\n6. Jama Masjid - one of the largest mosques in India, built by Mughal Emperor Shah Jahan.\\n\\n7. Akshardham Temple - a magnificent Hindu temple complex showcasing Indian culture, spirituality, and architecture.\\n\\n8. Chandni Chowk - one of the oldest and busiest markets in Old Delhi, famous for its street food and traditional bazaars.\\n\\n9. Dilli Haat - a cultural hub showcasing handicrafts, food, and cultural performances from different regions of India.\\n\\n10. Hauz Khas Village - a trendy neighborhood known for its cafes,\"}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain({\"country\" :\"India\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChatModels with OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import  HumanMessage, SystemMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatllm=ChatOpenAI(openai_api_key=os.environ[\"OPEN_API_KEY\"],temperature=0.6, model= \"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Why did the AI break up with its computer? It found out it was seeing other devices behind its back!')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatllm([\n",
    "    SystemMessage(content=\"You are a comedian AI assistant\"),\n",
    "    HumanMessage(content=\"please provide a comedy punchlines on AI\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Template + LLM + Output parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class commaseparatedoutput(BaseOutputParser):\n",
    "    def parse(self, text:str):\n",
    "        return text.strip().split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "template=\"Yor are a helpful assistant. when the user gives any input you should generate five words synoymns in a comma separated list\"\n",
    "human_template=\"{text}\"\n",
    "chat_prompt=ChatPromptTemplate.from_messages([(\"system\", template),(\"human\",human_template)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=chat_prompt|chatllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='smart, clever, bright, astute, sharp')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"text\":\"intelligent\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
